{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909852be",
   "metadata": {},
   "source": [
    "# Credit - https://arminnorouzi.github.io/posts/2023/05/blog-post-13/\n",
    "\n",
    "'''\n",
    "GAN is a type of neural network that consists of two networks , a generator and a discriminator.\n",
    "The Generator tries to creeate new data samples that are similar to the input data , while the discriminator tries to distinguish between real and fake data samples\n",
    "\n",
    "Transformer used for language translation , text summerization and language modelling - consist of an encoder and decoderthat work together to process input sequence and generate output sequences .  The encoder process the input sequence and prodes a hidden representation of input , the decoder then takes the hidden representation and generates the output seqence\n",
    "\n",
    "GAN is used for generative tasks , while transformer is used for task related to NLP , GAN generate new samples while transformers tranforms input sequence into output sequence\n",
    "\n",
    "BENIFITS OF TRANSFORMERS OVER RNN AND LSTM\n",
    "-------------------------------------------\n",
    "\n",
    "> Long-Term dependencies\n",
    "> Parallelization\n",
    "> Handle variable-length inputs\n",
    "> Attention-based mechanism\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9ae75-2181-4a4b-b26e-d13beffcffd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:41.563079Z",
     "start_time": "2024-06-02T12:33:17.015654Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U tensorflow-text tensorflow\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b1636-3a39-414a-8de6-38198168333f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:41.579185Z",
     "start_time": "2024-06-02T12:33:41.564358Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d39a0-0335-4976-a64d-6761d9f0a8d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:41.718019Z",
     "start_time": "2024-06-02T12:33:41.580451Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples,metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                              with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples,val_examples = examples['train'],examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b77b4-a866-4fbf-81dc-fc54ff7c1b8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:41.796942Z",
     "start_time": "2024-06-02T12:33:41.719521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#visualizing Example sentences\n",
    "for pt_examples,en_examples in train_examples.batch(3).take(1):\n",
    "    print('> Examples in Portugese:')\n",
    "    for pt in pt_examples.numpy():\n",
    "        print(pt.decode('utf-8'))\n",
    "    print()\n",
    "    \n",
    "    print('> Examples in English:')\n",
    "    for pt in en_examples.numpy():\n",
    "        print(pt.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3de61-fb23-47f2-ab7a-059505cd7cff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:41.828210Z",
     "start_time": "2024-06-02T12:33:41.798049Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the tokenizer\n",
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='data',cache_subdir='',extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dfd432-acd8-492c-8fd3-4f8e5a9f2152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:42.658723Z",
     "start_time": "2024-06-02T12:33:41.829249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(f'data/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0195fe-a3a3-4732-8f26-7be15f0a956a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:42.674478Z",
     "start_time": "2024-06-02T12:33:42.659765Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Checking tokenize examples\n",
    "print('> This is a batch of strings:')\n",
    "for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2eab05-1995-438e-b2d7-75c25821a9f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:42.977438Z",
     "start_time": "2024-06-02T12:33:42.675594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "print('> This is a padded-batch of token IDs:')\n",
    "for row in encoded.to_list():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb534cbf-95c1-48fd-91a4-eb20c52741fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:43.118694Z",
     "start_time": "2024-06-02T12:33:42.978661Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "print('> This is human-redable text:')\n",
    "for line in round_trip.numpy():\n",
    "    print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94546e2f-b279-4cdd-9dfe-b7c562fd2d6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:43.150297Z",
     "start_time": "2024-06-02T12:33:43.121993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('> This is the text split into tokens:')\n",
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f0cf66-d105-477a-bd5d-c3058601c31c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:48.414112Z",
     "start_time": "2024-06-02T12:33:43.151328Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for pt_examples,en_examples in train_examples.batch(1024):\n",
    "    pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
    "    lengths.append(pt_tokens.row_lengths())\n",
    "    \n",
    "    en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "    lengths.append(en_tokens.row_lengths())\n",
    "    print('.',end='',flush=True)\n",
    "    \n",
    "all_lengths = np.concatenate(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92011a11-c53c-4c86-866b-e55f65af6a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:48.647124Z",
     "start_time": "2024-06-02T12:33:48.415114Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(all_lengths,np.linspace(0,500,101))\n",
    "plt.ylim(plt.ylim())\n",
    "avg_length = all_lengths.mean()\n",
    "plt.plot([avg_length,avg_length],plt.ylim())\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length,max_length],plt.ylim())\n",
    "plt.title(f'Maximum tokens per example : {max_length} and average tokens per example : {avg_length}');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263e09a-bcf2-438b-9b32-b27eed477ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:48.662597Z",
     "start_time": "2024-06-02T12:33:48.648402Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setting up data Pipeline\n",
    "MAX_TOKENS=128\n",
    "def prepare_batch(pt,en):\n",
    "    \"\"\"\n",
    "    Preprocess a batch of porteguse and english sentences for training a machine translation model.\n",
    "    \n",
    "    Args:\n",
    "        pt: A tensor of porteguse sentences of shape (batch_size,) and dtype tf.string\n",
    "        en: A tensor of english sentences of shape (batch_size,) and dtype tf.string\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of two tensors representing the input and output sequences for the model,and a tensor of shape (batch_size,max_length)\n",
    "        representing the ground truth out sequences . The input sequence tensor has shape (batch_size,max_length) and dtype tf.int64, \n",
    "        and the output sequence has shape (batch_size,max_length) and dtype tf.int64\n",
    "    \"\"\"\n",
    "    \n",
    "    pt = tokenizers.pt.tokenize(pt)\n",
    "    pt = pt[:,:MAX_TOKENS]\n",
    "    pt = pt.to_tensor()\n",
    "    \n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en[:, :(MAX_TOKENS+1)]\n",
    "    en_inputs = en[:,:-1].to_tensor()\n",
    "    en_labels = en[:,1:].to_tensor()\n",
    "    \n",
    "    return (pt,en_inputs),en_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21255b1d-7636-42d5-8938-b756d546aa85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:48.678218Z",
     "start_time": "2024-06-02T12:33:48.663678Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f0683-03ae-409b-8359-7f11ef664cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:48.694286Z",
     "start_time": "2024-06-02T12:33:48.679555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "    return(\n",
    "        ds.shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(prepare_batch,tf.data.AUTOTUNE)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794634cd-e43b-44ec-8730-4468b366fd70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:50.037901Z",
     "start_time": "2024-06-02T12:33:48.695461Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)\n",
    "\n",
    "for (pt,en),en_labels in train_batches.take(1):\n",
    "    break\n",
    "    \n",
    "print(f'pt.shape : {pt.shape}')\n",
    "print(f'en_labels.shape : {en_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508b268-973b-4b3a-8bb0-db3bd9b9ad31",
   "metadata": {},
   "source": [
    "\n",
    "attention layer do not rely on the order of the token in the input sequence , \n",
    "becuase the model does not contain any recurrent or convolutional layers that would inheritly capture the sequence order.\n",
    "\n",
    "To overcome this - Transformer model adds Positional encoding to the embedding vectors . \n",
    "the positional Encoding uses a set of sines and cosines at different frequencies accross the sequence\n",
    "\n",
    "https://www.youtube.com/watch?v=dichIcUZfOw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ea833-b8e0-41f4-b912-6ea54cea2398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:50.053518Z",
     "start_time": "2024-06-02T12:33:50.038940Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length,depth):\n",
    "    '''\n",
    "    Generates a matrix of position encodings for an input sequence.\n",
    "    \n",
    "    Args:\n",
    "        length: An integer representing the length of the input sequence\n",
    "        depth: An integer representing the dimentionality of the encoding\n",
    "        \n",
    "    Returns:\n",
    "        A tf.tensor of shape '(length,depth)' representing the position encoding matrix\n",
    "    '''\n",
    "    \n",
    "    depth = depth/2\n",
    "    \n",
    "    positions = np.arange(length)[:,np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis,:]/depth\n",
    "    \n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads),np.cos(angle_rads)],\n",
    "        axis=-1)\n",
    "    \n",
    "    return tf.cast(pos_encoding,dtype= tf.float32)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63118cfa-f44d-46cd-827e-27441f25cafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:50.839006Z",
     "start_time": "2024-06-02T12:33:50.054518Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_encoding = positional_encoding(length=2048,depth=512)\n",
    "\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding.numpy().T,cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a64bb-e42e-496a-a304-70b85dd27fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.171725Z",
     "start_time": "2024-06-02T12:33:50.843078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_encoding /= tf.norm(pos_encoding,axis=1,keepdims=True)\n",
    "p = pos_encoding[1000]\n",
    "dots = tf.einsum('pd,d -> p',pos_encoding,p)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(dots)\n",
    "plt.ylim([0,1])\n",
    "plt.plot([950,950,float('nan'),1050,1050],\n",
    "        [0,1,float('nan'),0,1],color='k',label='Zoom')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(dots)\n",
    "plt.xlim([950,1050])\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f818d7-e930-4fec-ae77-34e161e49c26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.187129Z",
     "start_time": "2024-06-02T12:33:51.172917Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    This Layer combines the input embedding with a positional encoding that helps the transformer to understand\n",
    "    the relative position of the tokens in sequence . Takes an input sequence of tokens and converts it to a sequence \n",
    "    of embedding vectors, then adds positional information to it\n",
    "    '''\n",
    "    def __init__(self,vocab_size,d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size,d_model,mask_zero=True)\n",
    "        self.pos_encoding = positional_encoding(length=2048,depth=d_model)\n",
    "        \n",
    "    def compute_mask(self,*args,**kwargs):\n",
    "        return self.embedding.compute_mask(*args,**kwargs)\n",
    "    \n",
    "    def call(self,x):\n",
    "        length= tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis,:length,:]\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01974452-fbd8-4a57-a878-b8a1aba70e69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.296886Z",
     "start_time": "2024-06-02T12:33:51.188232Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size(),d_model=512)\n",
    "embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size(),d_model=512)\n",
    "\n",
    "pt_emb = embed_pt(pt)\n",
    "en_emb = embed_en(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e0ff7089a7766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.312409Z",
     "start_time": "2024-06-02T12:33:51.297885Z"
    }
   },
   "outputs": [],
   "source": [
    "en_emb._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a3be85defb30b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.328475Z",
     "start_time": "2024-06-02T12:33:51.313684Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm  = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6ffee22cdf48ac7",
   "metadata": {},
   "source": [
    "#How Attention Works ?\n",
    "\n",
    "In an attention layer , there are two inputs the query sequence and the context sequence.\n",
    "the query sequence is the sequence being processes wheereas the context sequence is the seqence being  \n",
    "attended to . the output has the same shape as the query sequence.\n",
    "\n",
    "the operation of attetion is similar  to  dict lookup - but insted of returning exact match  it  returns fuzzy match\n",
    "an attention layer works  similarly to a fuzzy dictionary lookup,but insted of returning a single value, \n",
    "it combines multiple values based on how well they match with the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86a2e9c50c879a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.344472Z",
     "start_time": "2024-06-02T12:33:51.329697Z"
    }
   },
   "outputs": [],
   "source": [
    "#The cross attention layer : Decoder-Encoder attention\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self,x,context):\n",
    "        attn_output,attn_scores = self.mha(\n",
    "            query=x,\n",
    "            key=context,\n",
    "            value=context,\n",
    "            return_attention_scores=True\n",
    "        )\n",
    "        \n",
    "        self.last_attn_scores = attn_scores\n",
    "        \n",
    "        x =  self.add([x,attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8dace4b4741891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.485910Z",
     "start_time": "2024-06-02T12:33:51.345472Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_ca = CrossAttention(num_heads=2,key_dim=512)\n",
    "\n",
    "print(pt_emb.shape)\n",
    "print(en_emb.shape)\n",
    "print(sample_ca(en_emb,pt_emb).shape)\n",
    "# the output length is the length of the query sequence and not the  length of the context \"key/value\" space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597fc97d999b78b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.501755Z",
     "start_time": "2024-06-02T12:33:51.489017Z"
    }
   },
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self,x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            key=x, \n",
    "            value=x\n",
    "        )\n",
    "        x = self.add([x,attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176318c9dc78301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.578134Z",
     "start_time": "2024-06-02T12:33:51.503756Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_gsa = GlobalSelfAttention(num_heads=2,key_dim=512)\n",
    "\n",
    "print(pt_emb.shape)\n",
    "print(sample_gsa(pt_emb).shape)\n",
    "#output tensor has the same shape as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c017c52f7eeae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.593819Z",
     "start_time": "2024-06-02T12:33:51.581770Z"
    }
   },
   "outputs": [],
   "source": [
    "#the causal self  attention layer : Decoder  self-attention\n",
    "#used when the output of each timestep can only depend  on previous time  steps,and not  in future time steps.\n",
    "#in such task the causal self-attention layer is used to enforce the constraint that the model can only attend to the previous time steps during decoding process\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self,x):\n",
    "        attn_output = self.mha(\n",
    "            query = x,\n",
    "            value=x, \n",
    "            key=x, \n",
    "            use_causal_mask=True\n",
    "        )\n",
    "        x = self.add([x,attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b8ff8ccead023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.640121Z",
     "start_time": "2024-06-02T12:33:51.594820Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_csa = CausalSelfAttention(num_heads=2,key_dim=512)\n",
    "\n",
    "print(en_emb.shape)\n",
    "print(sample_csa(en_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6761312f704956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.686646Z",
     "start_time": "2024-06-02T12:33:51.641226Z"
    }
   },
   "outputs": [],
   "source": [
    "# TheOutput of the  early  sequence  elements does  not depend  on later elements,\n",
    "# so it should not matter if you trim elements before of after applying the layer\n",
    "out1 = sample_csa(embed_en(en[:,:3]))\n",
    "out2 = sample_csa(embed_en(en))[:,:3]\n",
    "\n",
    "tf.reduce_max(abs(out1-out2)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdac00ca3931392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.702641Z",
     "start_time": "2024-06-02T12:33:51.687698Z"
    }
   },
   "outputs": [],
   "source": [
    "#The feed forward network\n",
    "#FeedForward class implements feedforward neural network,\n",
    "#used in Transformer based model to process each token representation\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,diff,dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq= tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(diff,activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add  = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.add([x,self.seq(x)])\n",
    "        x=self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b9d3d592aee7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.749773Z",
     "start_time": "2024-06-02T12:33:51.703642Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_ffn = FeedForward(512,2048)\n",
    "print(en_emb.shape)\n",
    "print(sample_ffn(en_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e5ec0333cd3cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.765326Z",
     "start_time": "2024-06-02T12:33:51.750903Z"
    }
   },
   "outputs": [],
   "source": [
    "#The Encoder\n",
    "'''\n",
    "The Encoder consists of a  PositionalEmbedding layer at the input and a stck of EncoderLayer Layers. \n",
    "Each EncoderLayer contains a GlobalSelfAttention and FeedForward layer\n",
    "'''\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,*,d_model,num_heads,dff,dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention =GlobalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        self.ffn = FeedForward(d_model,dff)\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22b9d48a18f99c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:33:51.780896Z",
     "start_time": "2024-06-02T12:33:51.766625Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,*,num_layers,d_model,num_heads,dff,vocab_size,dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.pos_embedding = PositionalEmbedding(\n",
    "            vocab_size=vocab_size,\n",
    "            d_model=d_model\n",
    "        )\n",
    "        \n",
    "        self.enc_layers =[\n",
    "            EncoderLayer(d_model=d_model,\n",
    "                         num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate) \n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def  call(self,x):\n",
    "        x = self.pos_embedding(x)\n",
    "        x  = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163ae7be7a1c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:36:42.303046Z",
     "start_time": "2024-06-02T12:36:39.103759Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing the Encoder\n",
    "with tf.device(\"CPU\"):\n",
    "    sample_encoder = Encoder(num_layers=4,\n",
    "                             d_model=512,\n",
    "                             num_heads=8,\n",
    "                             dff=2048,\n",
    "                             vocab_size=8500)\n",
    "    sample_encoder_output = sample_encoder(pt,training=False)\n",
    "    \n",
    "    print(pt.shape)\n",
    "    print(sample_encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85290a54e27cf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:36:46.663244Z",
     "start_time": "2024-06-02T12:36:46.649150Z"
    }
   },
   "outputs": [],
   "source": [
    "#The Decoder\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    A single layer of the decoder in a transformer  based architecture\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 dropout_rate=0.1):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        \n",
    "        self.causal_self_attention = CausalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.ffn = FeedForward(d_model,dff)\n",
    "        \n",
    "    def call(self,x,context):\n",
    "        x = self.causal_self_attention(x=x)\n",
    "        x = self.cross_attention(x=x,context=context)\n",
    "        # caching the last attention score for plotting later\n",
    "        self.last_attn_score = self.cross_attention.last_attn_scores\n",
    "        x = self.ffn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c25f3164c88a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:36:47.513202Z",
     "start_time": "2024-06-02T12:36:47.505372Z"
    }
   },
   "outputs": [],
   "source": [
    "# The decoder class\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,*,num_layers,d_model,num_heads,dff,vocab_size,dropout_rate=0.1):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                                 d_model=d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model,\n",
    "                         num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "        self.last_attn_scores = None\n",
    "        \n",
    "    def call(self,x,context):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x,context)\n",
    "        \n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_score\n",
    "        return x\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03fa3934e13460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:48.669053Z",
     "start_time": "2024-06-02T12:37:41.568351Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing the decoder\n",
    "with tf.device(\"CPU\"):\n",
    "    sample_decoder = Decoder(num_layers=4,\n",
    "                             d_model=512,\n",
    "                             num_heads=8,\n",
    "                             dff = 2048,\n",
    "                             vocab_size=8000)\n",
    "    \n",
    "    output = sample_decoder(\n",
    "        x = en,\n",
    "        context = pt_emb\n",
    "    )\n",
    "    \n",
    "    print(en.shape)\n",
    "    print(pt_emb.shape)\n",
    "    print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72e3c91710f707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:49.689239Z",
     "start_time": "2024-06-02T12:37:49.673215Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_decoder.last_attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c00a6825844995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:50.576219Z",
     "start_time": "2024-06-02T12:37:50.564743Z"
    }
   },
   "outputs": [],
   "source": [
    "#THE TRANSFORMER\n",
    "class Transformer(tf.keras.Model):\n",
    "    #A model that consists of encode decoder and final dense layer\n",
    "    def __init__(self,*,num_layers,d_model,num_heads,dff,input_vocab_size,target_vocab_size,dropout_rate =  0.1):\n",
    "        super().__init__()\n",
    "        self.encoder =  Encoder(num_layers=num_layers,\n",
    "                                d_model=d_model,\n",
    "                                num_heads=num_heads,\n",
    "                                dff=dff,\n",
    "                                vocab_size=input_vocab_size,\n",
    "                                dropout_rate=dropout_rate)\n",
    "        \n",
    "        self.decoder =  Decoder(num_layers=num_layers,\n",
    "                                d_model=d_model,\n",
    "                                num_heads=num_heads,\n",
    "                                dff=dff,\n",
    "                                vocab_size=target_vocab_size,\n",
    "                                dropout_rate=dropout_rate)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        context,x =  inputs\n",
    "        context = self.encoder(context)\n",
    "        x = self.decoder(x,context)\n",
    "        logits = self.final_layer(x)\n",
    "        \n",
    "        try:\n",
    "            del  logits._keras_mask\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40c7619e64a4ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:51.717253Z",
     "start_time": "2024-06-02T12:37:51.620423Z"
    }
   },
   "outputs": [],
   "source": [
    "num_layers  =  4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
    "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
    "    dropout_rate=dropout_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63385ad0539e59c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:53.580090Z",
     "start_time": "2024-06-02T12:37:52.647396Z"
    }
   },
   "outputs": [],
   "source": [
    "output = transformer((pt,en))\n",
    "print(en.shape)\n",
    "print(pt.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3577b5a42e673e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:53.604951Z",
     "start_time": "2024-06-02T12:37:53.582225Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c308ff20c26ce29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:54.614980Z",
     "start_time": "2024-06-02T12:37:54.608080Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "#Optimizer\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,d_model,warmup_steps=4000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        \n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self,step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model)*tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502d5161ebfdff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:55.729446Z",
     "start_time": "2024-06-02T12:37:55.725238Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,beta_1=0.9,beta_2=0.98,epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f02a251caa391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:57.186923Z",
     "start_time": "2024-06-02T12:37:57.035805Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(learning_rate(tf.range(40000,dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9882e90528bdcdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:58.054978Z",
     "start_time": "2024-06-02T12:37:58.050684Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_loss(label,pred):\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True,reduction='none'\n",
    "    )\n",
    "    loss = loss_object(label,pred)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *=  mask\n",
    "    loss = tf.reduce_mean(loss)/tf.reduce_sum(mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b92e93a2666d9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T12:37:58.955774Z",
     "start_time": "2024-06-02T12:37:58.947608Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_accuracy(label,pred):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "    \n",
    "    mask = label != 0\n",
    "    match = match & mask\n",
    "    \n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7182f454e3a139c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-02T12:38:40.700525Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "with tf.device(\"CPU\"):\n",
    "    transformer.compile(loss=masked_loss,\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=[masked_accuracy])\n",
    "    \n",
    "    transformer.fit(train_batches,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae628cdd352fdfba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:03:52.151111Z",
     "start_time": "2024-06-02T14:03:51.310342Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "#Translator  Class\n",
    "class Translator(tf.Module):\n",
    "    def __init__(self,tokenizers,transformer):\n",
    "        self.tokenizers = tokenizers\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def __call__(self,sentence,max_length=MAX_TOKENS):\n",
    "        assert isinstance(sentence,tf.Tensor)\n",
    "        if len(sentence.shape) == 0:\n",
    "            sentence = sentence[tf.newaxis]\n",
    "        sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "        encoder_input = sentence\n",
    "        \n",
    "        start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "        start = start_end[0][tf.newaxis]\n",
    "        end = start_end[1][tf.newaxis]\n",
    "        \n",
    "        outtput_array = tf.TensorArray(dtype = tf.int64,size = 0 ,dynamic_size = True)\n",
    "        outtput_array = outtput_array.write(0,start)\n",
    "        \n",
    "        for i in tf.range(max_length):\n",
    "            output = tf.transpose(outtput_array.stack())\n",
    "            predictions = self.transformer([encoder_input,output],training=False)\n",
    "            \n",
    "            predictions = predictions[:-1:,:]\n",
    "            predicted_id = tf.argmax(predictions,axis=1)\n",
    "            \n",
    "            output_array = outtput_array.write(i+1,predicted_id[0])\n",
    "            \n",
    "            if predicted_id == end:\n",
    "                break\n",
    "                \n",
    "            output = tf.transpose(output_array.stack())\n",
    "            text = tokenizers.en.detokenize(output)[0]\n",
    "            \n",
    "            tokens = tokenizers.en.lookup(output)[0]\n",
    "            \n",
    "            self.transformer([encoder_input,output[:,:-1]],training=False)\n",
    "            attention_weights = self.transformer.decoder.last_attn_scores\n",
    "            return text,tokens,attention_weights\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b48ca40894e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:04:58.832147Z",
     "start_time": "2024-06-02T14:04:58.808944Z"
    }
   },
   "outputs": [],
   "source": [
    "translator=Translator(tokenizers,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca712ab661be1463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:56:30.676114Z",
     "start_time": "2024-06-02T14:56:30.671506Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_translation(sentence,tokens,ground_truth):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'{\"Prediction:\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
    "    print(f'{\"Ground truth:\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67027dfe05412352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
